---
title:  "ML 기초"
layout: single
categories: code
tag: ML
toc: true
use_math: true #수학식 적용여부
author_profile: false #내 프로파일 안보이기
sidebar:
    nav: "docs" 
# search: false #검색불가
---
## 데이터
### 정형데이터 : 숫자
### 비정형 데이터
#### 텍스트
#### 이미지
눈은 색보다 밝기에 민감하다.
jpg는 용량을 줄이기 위해 밝기 정보와 Cb Cr이라는 두가지 색차 정보로 저장된다.
사진은 PNG가 좋다.

JPEG, JPG (Joint Photographic Experts Group)
: 정지 화상을 위해서 만들어진 손실 압축 방법 표준이다. 
(JPEG 를 사용하는 파일 형식들도 보통 JPEG 이미지라 불리며, .jpg, .jpeg, .jpe 등의 확장자를 사용한다. 손실 압축 형식이지만 파일크기가 작기 때문에 웹에서 널리 쓰인다. 압축률을 높이면 파일 크기는 작아지지만 이미지 품질은 더욱 떨어진다.)

PNG(Portable Network Graphics)
: 비손실 그래픽 파일 포맷, 투명성 값도 포함
(무손실 압축으로 이미지 디테일 손실이 전혀없고 고품질 이미지를 생성하지만 파일 크기는 상대적으로 다른 포맷보다 커진다.)

GIF(Graphics Interchange Format)
: PNG 포맷 이전에 개발된 비손실 그래픽 포맷 중의 하나이다.
(1개의 파일에 여러 개의 이미지를 저장할 수 있는데, 다수의 이미지를 하나의 이미지처럼 복수 처리하여 간단한 애니메이션 효과를 낼 수 있다. 웹 페이지 상에서 움직이는 그림(움짤)은 GIF 를 사용한다. )

#### 영상
코덱(Codec) = Coder + Decoder 
압축, 변환과정 Encoding 
##### 디스플레이
물감은 감산혼합 잉크
디스플레이는 가산혼합 빛
색 재현율
: 화면에서 나타낼수있는 색의 범위 , sRGB/Adobe RGB(프린터를 위한)/ DCI-P3(영화를 위한)
##### 해상도
화소
: 색을 나타내는 점
화질 = 해상도 + 명암비 + 색표현
16:9
1080p (ex. 1920*1080, 순차주사 Progressive scan)
1080i (ex. 2560*1080, 비월 주사 Interlaced sacn)
720p HD
1080p Full HD
1440p Quad HD
2160p Ultra HD
#### 음성
## 인공지능
사고나 학습등 인간이 가진 지적 능력을 컴퓨터를 통해 구현하는 기술

## 머신러닝
컴퓨터가 스스로 학습하여 인공지능의 성능을 향상시키는 기술 방법


### 지도학습(supervised learning)
: 정답 라벨로 학습

#### 회귀 (regression) 
: 유전체 선발, 시장 예측 - Random forest, Regression, 정규화 (regularization)

##### 선형회귀(linear regression)
손실을 최소화하는 파라미터 계산
$y = wx + b$
평균제곱오차 비교 : **각 데이터마다 y값 오차를 제곱하여 데이터갯수로 나누어 평균**을 해서 나온값을 비교
데이터 분포를 시각화 해서 적용가능한지 먼저 판단

**a,b로 정리하면 다항2차 방정식이** 나오는데 이것으로 최소값을 찾는다.

##### 정규화 (regularization)
과적합을 막는 방법중 하나

[손실함수](https://truman.tistory.com/164)
- 손실 함수는 실제값과 예측값의 차이(loss, cost)를 수치화해주는 함수이다. 
- 오차가 클수록 손실 함수의 값이 크고, 오차가 작을수록 손실 함수의 값이 작아진다.
- 평균제곱오차도 하나의 손실함수

정규화 항($\alpha$)을 조정하여 절댓값차이를 줄임

#### 분류 (classification) 
: 패턴 인식, 의학 진단 -  k-nn(K-nearest neighbor), SVM (Support Vector Machine), Logistic regression, Naive Bayes, Decision Tree

##### 로지스틱 회귀 (Logistic regression)
집단 각각에 속하는 확률 계산

이진분류는 시그모이드함수 활용(임계값 기준으로 1혹은 0) 또는 결정경계

손실함수로는 주로 경사하강법 이용

##### Naive Bayes
자연어 분류에 많이 이용되는 알고리즘
확율에 따른 결과를 예측하는 알고리즘
문장속 단어가 나타나는 비율, 단어 각각의 조건부 확률 등 문장을 구성하는 단어 정보를 사용해 확률 계산의 정확도를 높인다.
독립사건의 영향을 다룰때 사용한다.

##### 결정트리 (Decision Tree)
학습데이터를 나누면서 문제를 해결
데이터의 불균형을 나타내는 불순도를 수치화

앞의 두과정을 반복

#### 회귀, 분류 둘다가능한 알고리즘
SVM (Support Vector Machine)/- with kernel, random forest,K-nn(K-nearest neighbor), neural network

##### SVM (Support Vector Machine)
집단 데이터 사이의 마진을 최대화해서 좋은 결정경계를 구한다.

하드마진 : 마진안에 데이터 허용X
소프트마진 : 마진안에 데이터 허용

마진선에 있는 데이터와 안에있는 데이터를 기준으로 경계를 정한다.
이 기준 파라미터 정하는 방식으로 그리드 탐색과 랜덤 탐색이 있다.

##### SVM (Support Vector Machine) + 커널 kernel
선이 아니더라도 차원을 늘려서 경계를 만들수있다.(선형, 시그모이드, 다항(원형태), RBF 커널)

##### 랜덤 포레스트 (random forest)
결정트리를 어러번 중첩시켜 사용 다수결로 결과를 도출
다른 다양한 결과를 얻기 위해
1. 부트스트랩(bootstrap)
: 학습 데이터에서 여러번 무작위로 복원(반복) 추출
1. 특징 임의 선택
: 부트스트랩으로 만든 학습데이터에 일부 특징만을 임의로 선택 사용

##### 신경망 (neural network)
분류에 많이 사용된다.
생물의 신경망을 따서 만듬, 딥러닝에 활용
입력층 은닉층 출력층 
$y=f(w_0+w_1x_1+w_2x_2)$
$w_1,w_2$는 가중치 $w_0$는 편향 bias 를 활성화 함수($f$)에 적용 
과적합을 막기위해 학습조기종료

##### k-최근접 이웃 알고리즘(kNN, K-nearest neighbor)
학습데이트를 저장하여 입력데이터와의 거리를 계산하여 근처에 있는 k개의 점까지 데이터를 어떻게 분류하는지를 보고다수결로 결정

### 비지도 학습(unsupervised learning) 
: 정답없이 학습

#### 군집 (clustering) 
: 시장 세분화/ 추천자 시스템 - k-means, 가우시안 혼합모델(Gaussian Mixture models), Kierarchical clistering
##### k-평균알고리즘 (k-means)
##### 가우시안 혼합모델(Gaussian Mixture models)

#### 차원축소 (dimensionality reduction) 
: 특징 추출/ 빅데이터 시각화 - 주성분 분석(PCA, principal component analysis), 잠재 의미분석(LSA, latent semantic analysis), 음수 미포함 행렬 분해(NMF, non-negative matrix factorization), 잠재 디리클레 할당(LDA, latent Dirichlet allocation), 국소 선형 임베딩(LLE, local linear embedding), t-분포 확률적 임베딩(t-SNE, t-distributed stochastic neighbor embedding)

##### 주성분 분석 (PCA, principal component analysis)
상관관계가 있는 다변량 데이터를 주성분으로 간경하게 나타낼 수있다.
원본 데이터를 가공해 새로운 변수로 구성
방향과 중요도를 찾아서 가장 큰값을 주성분으로 잡는다. 두번쩨 큰값을 두번쩨 주성분으로 잡는다.

##### 잠재 의미 분석 (LSA, latent semantic analysis)
##### 음수 미포함 행렬 분해(NMF, non-negative matrix factorization)
##### 잠재 디리클레 할당(LDA, latent Dirichlet allocation)
##### 국소 선형 임베딩(LLE, local linear embedding)
##### t-분포 확률적 임베딩(t-SNE, t-distributed stochastic neighbor embedding)

### 강화 학습 (reinforcement learning)
: 시뮬레이션 반복학습, 로봇탐색/ 인공지능 게임 - 



## 딥러닝
인간의 뉴런과 비슷한 인공신경망 방식으로 정보를 처리 (비지도 학습)

CNN 합성곱 신경망
RNN 순환 신경망
GANs 생성적 적대 신경망
RBM
심층 강화학습