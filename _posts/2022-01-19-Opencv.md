---
title:  "ComputerVision"
layout: single
categories: code
tag: [ML,Opnecv, cv2]
toc: true
use_math: true #수학식 적용여부
author_profile: false #내 프로파일 안보이기
sidebar:
    nav: "docs" 
# search: false #검색불가
---

## Opnecv, cv2

1. 데이터 입력 : 이미지 혹은 동영상
1. 전처리 : 이미지 표준화, 색변환 등등
1. 특징추출 : 구별가능한 정보 찾기
1. 머신러닝 모델 : 특징을 학습, 예측혹은 분류

### 이미지 입력
 2차원으로 표현
 회색조일때는 빛의 강도
 컬러일때는 RGB값의 강도를 표기

### 이미지 전처리
- 이미지 표준화 : 같은 크기로 리사이즈
- 데이터 강화  : 기존의 데이터셋에 포함된 이미지를 조금씩 변형해서 새 데이터로 추가
- 그 외 : 배경 제거, 회색처리, 밝기 조절...

### 특징 추출
일반 머신 러닝과 달리 이 분야의 딥러닝은 특징을 딥러닝에서 자동 추출되기에 상대적으로 어려움이 없다.

신경망이 모든 특징을 찾아 학습중에 가중치를 조정한다.

## 신경 쓰야하는 부분
### 성능지표
정확도 : 가장 간단한 방법
#### 혼동행렬
- 혼동 행렬 (confusion matrix)
: TN 실제 부정 데이터를 부정으로 제대로 예측, FP 실제 부정 데이터를 긍정으로 잘못 예측, FN 실제 긍정 데이터를 부정으로 잘못 예측, TP 실제 긍정 데이터를 긍정으로 제대로 예측 (행렬표시)

- 정확도 (accuracy)
: 전체 결과 중 정확하게 예측한 비율

- 정밀도 (precision)
: 실제 긍정으로 예측한 결과 중 정말 긍정인 비율

- 재현율 (recall)
: 실제 긍정인 대상을 긍정으로 제대로 예측한 비율

- F값 (F1-score)
: 정밀도와 재현율을 다 고려한 값

### 베이스라인 모델 설정하기
전이학습 : 기존에 있는 모델에서 향상

- 어떤 유형의 신경망을 사용?
- YOLO 나 SSD 등 물체 인식 기법을 적용 해야하나?
- 신경망의 층수는 얼마나?
- 활성화 함수는 어떤 것?
- 촤적화알고리즘은 ?
- 드롭아웃 배치정규화등 과적합방지?

테스트셋이 많지 않다면, 60:20:20, 70:15:15

그러나 1백만개 이상의 데이터셋이면 각각 만개씩 줘도 된다.

#### 전처리
- 회색조 이미지 변환
- 이미지 크기 동일하게 조절
- 데이터 정규화
    - 값은 작게 [0,1]안에
    - 값의 범위는 동일하게
    - 예 : 각 픽셀값에 평균을 뻬고 표준편차로 나눈다.
- 데이터 강화

### 평가 및 성능지표 해석
### 과적합 징후
- 훈련 데이터 성능은 높지만 검증데이터 성능이 낮다면 과적합
- 훈련 데이터 성능이 낲으면 과소적합

### 학습 곡선 그리기
verbose=1 이면 진행 에폭을 프린트 해준다.
### 파라미터 튜닝
#### 데이터 수집
과적합일 경우 유효하다.
과소적합시 모델성능을 의심해야한다.
#### 파라미터와 하이퍼 파라미터
파라미터는 : 내부에서 생성되어 전달되는 파라미터
하이퍼파라미터 : 값을 정할수있는 파라미터
- 신경망 구조
    - 은닉층 수(신경망 깊이) : 데이터의 복작도 맞춰 수가 많아져야한다.
    - 각 층의 뉴런 수 (층의 폭) : 데이터의 복작도 맞춰 수가 많아져야한다.
    - 활성화 함수 종류 

- 학습 및 최적화
    - 학습률 : 최적을 중간에 찾음 굿, 끝까지 못 찾는 다면, 에포크를 늘리든 학습률을 올린다. 검정손실이 증감이 반복하면 학습률을 줄인다.
        - 작은 학습률: 손실함수는 감수하지만 너무 느림
        - 큰 학습률: 손실은 줄지만 최소점에 도달하기 어렵다.
        - 아주 큰 학습률: 초기는 감소하지만 다시 증가한다.
        - 변동형 학습률 값도 많이 이용된다.
    - 에포크 수 (조기종료 적용) : `EarlyStopping(monitor='val_loss', min_delta=0, patience=20)` 
        - monitor : 목적 지표
        - min_delta : 개선 중인지에 대한 기준이 되는 상승폭
        - patience : 과적합의 판단 기준, 연속으로 지표가 개선되지 않는 에포크 수 (넉넉히 주시오)
    - 미니배치 크기 : BGD, SGD, MB-GD
    - 최적화 알고리즘 종류
        - 모멘텀을 적용한 경사 하강법
        - Adam `keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=10^-8^,decay=0.0`

- 규제화 및 과적합 방지 기법
    - L2 규제화 : 가중치 감쇠
    - 드롭아웃 층 : 초기 0.3 (드롭아웃이 랜덤으로 진행되며 모든 셀들이 역할을 잘하도록 학습하도록 돕는다.)
    - 데이터 강화 : 데이트를 변형(돌리고, 크기변경)시켜 절대적 양을 추가한다. `datagen=ImageDataGenerator()` `datagen.fit(training_set)`

#### 배치 정규화
`from keras.layers.nomalization import BatchNormalization`
`model.add(BatchNormalization())`

### 신경망 구조
- LeNet : 5층 (3c+2fc)
- AlexNet : 8층 (5c+3fc)
- VGGNet : 하이퍼파라미터 조정
- 인셉션(GoogleNet) : 인셉션 층을 두어 층의 깊이 증가
- ResNet : 잔차블럭으로 지름길 연결로 값을 전달

### ROI 함수
```py
ret, img =  cap.read()

cv2.namedWindow('Select Window')
cv2.imshow('Select Window', img)

# setting ROI
rect = cv2.selectROI('Select Window', img, fromCenter= False, showCrosshair=True)
cv2.destroyWindow('Select Window')
```
### Object_Trackers
```py
OPENCV_OBJECT_TRACKERS = {
    "csrt": cv2.TrackerCSRT_create,
    "kcf": cv2.TrackerKCF_create,
    "boosting": cv2.TrackerBoosting_create,
    "mil": cv2.TrackerMIL_create,
    "tld": cv2.TrackerTLD_create,
    "medianflow":cv2.TrackerMedianFlow_create,
    "mosse": cv2.TrackerMOSSE_create
}
tracker = cv2.TrackerCSRT_create()
# initialize tracker
tracker.init(img, rect)
```

